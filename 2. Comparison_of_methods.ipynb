{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The manually labelled data is uploaded. Columns of the dataframe contain: name (name of the text note), text, spanish (having a binary class for 1 Spanish, 0 else), and sentiment."
      ],
      "metadata": {
        "id": "i-S9ofno6Aiq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nVgXdQ51Qvy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('/content/manual_labelling.xlsx')\n",
        "df = df.iloc[:, :-1]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT**"
      ],
      "metadata": {
        "id": "fOJhfDSc2vto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The necessary libraries are installed and imported."
      ],
      "metadata": {
        "id": "CrF_v_VP6ZgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysentimiento\n",
        "\n",
        "from pysentimiento import create_analyzer\n",
        "import transformers\n",
        "\n",
        "transformers.logging.set_verbosity(transformers.logging.ERROR)\n",
        "\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")"
      ],
      "metadata": {
        "id": "jsKs84AD2x0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiments are predicted with BERT and added in a column. The total number of sentiments for each cases are summed."
      ],
      "metadata": {
        "id": "ekYLZgLL6pN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    text = row['text']\n",
        "    result_df = analyzer.predict(text)\n",
        "\n",
        "    sentiments.append(result_df.output)\n",
        "\n",
        "df['BERT'] = sentiments\n",
        "\n",
        "positive_count = (df['BERT'] == 'POS').sum()\n",
        "neutral_count = (df['BERT'] == 'NEU').sum()\n",
        "negative_count = (df['BERT'] == 'NEG').sum()\n",
        "\n",
        "print(\"Positive:\", positive_count)\n",
        "print(\"Neutral:\", neutral_count)\n",
        "print(\"Negative:\", negative_count)"
      ],
      "metadata": {
        "id": "ENp8r7Kv3Pi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The format of the labels is modified.\n",
        "df['BERT'] = df['BERT'].replace({'POS': 'Positive', 'NEG': 'Negative', 'NEU': 'Neutral'})\n",
        "df"
      ],
      "metadata": {
        "id": "5c01z-u04IsA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AFINN**"
      ],
      "metadata": {
        "id": "MuBKA8_E2tDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install and import the necessary libraries."
      ],
      "metadata": {
        "id": "gtORMpsj71rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob\n",
        "from textblob import TextBlob, Word\n",
        "\n",
        "!pip install nltk\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import string\n",
        "\n",
        "\n",
        "import os\n",
        "stop_words = set(stopwords.words('spanish'))"
      ],
      "metadata": {
        "id": "UxFMp-_e4BBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we initialise an empty dictionary to store FINN lexicon. Afterwards, we load the AFINN lexicon from a CSV file into a DataFrame. Only the first two columns are used. the, we iterate through each row of the DataFrame, extracting the word and its sentiment score."
      ],
      "metadata": {
        "id": "DAq6O-t-8Anw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "afinn = {}\n",
        "\n",
        "lexicon_df = pd.read_csv('/content/lexico_afinn.csv', header=0)\n",
        "lexicon_df = lexicon_df.iloc[:, :2]\n",
        "\n",
        "for index, row in lexicon_df.iterrows():\n",
        "    word = row['palabra']\n",
        "    sentiment_score_str = row['puntuacion']\n",
        "\n",
        "    try:\n",
        "        sentiment_score = float(sentiment_score_str)\n",
        "        afinn[word] = sentiment_score\n",
        "    except ValueError:\n",
        "        print(f\"Invalid sentiment score '{sentiment_score_str}' for word '{word}'. Skipping row.\")"
      ],
      "metadata": {
        "id": "daDJbKb04XWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function that calculates the sentiment of the text. First, convert the text to lowercase and split it into words. Then, calculate the sentiment score by summing the scores of individual words using the AFINN dictionary."
      ],
      "metadata": {
        "id": "YoeDSbz4-VIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sentiment(text):\n",
        "    words = text.lower().split()\n",
        "    sentiment_score = sum(afinn.get(word, 0) for word in words)\n",
        "    if sentiment_score > 0:\n",
        "        return 'Positive'\n",
        "    elif sentiment_score < 0:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'"
      ],
      "metadata": {
        "id": "1D_vYreu4gJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also upload stopwords for Catalan and add them to those for Spanish."
      ],
      "metadata": {
        "id": "llbEy52j8Vd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catalan_stopwords = catalan_stopwords = [\n",
        "    'de', 'es', 'i', 'a', 'o', 'un', 'una', 'unes', 'uns', 'un', 'tot',\n",
        "    'també', 'altre', 'algun', 'alguna', 'alguns', 'algunes', 'ser', 'és',\n",
        "    'soc', 'ets', 'som', 'estic', 'està', 'estem', 'esteu', 'estan', 'com',\n",
        "    'en', 'per', 'perquè', 'per que', 'estat', 'estava', 'ans', 'abans',\n",
        "    'éssent', 'ambdós', 'però', 'per', 'poder', 'potser', 'puc', 'podem',\n",
        "    'podeu', 'poden', 'vaig', 'va', 'van', 'fer', 'faig', 'fa', 'fem',\n",
        "    'feu', 'fan', 'cada', 'fi', 'inclòs', 'primer', 'des de', 'conseguir',\n",
        "    'consegueixo', 'consigueix', 'consigueixes', 'conseguim', 'consigueixen',\n",
        "    'anar', 'haver', 'tenir', 'tinc', 'te', 'tenim', 'teniu', 'tene', 'el',\n",
        "    'la', 'les', 'els', 'seu', 'aquí', 'meu', 'teu', 'ells', 'elles', 'ens',\n",
        "    'nosaltres', 'vosaltres', 'si', 'dins', 'sols', 'solament', 'saber',\n",
        "    'saps', 'sap', 'sabem', 'sabeu', 'saben', 'últim', 'llarg', 'bastant',\n",
        "    'fas', 'molts', 'aquells', 'aquelles', 'seus', 'llavors', 'sota', 'dalt',\n",
        "    'ús', 'molt', 'era', 'eres', 'erem', 'eren', 'mode', 'bé', 'quant',\n",
        "    'quan', 'on', 'mentre', 'qui', 'amb', 'entre', 'sense', 'jo', 'aquell'\n",
        "]\n",
        "\n",
        "stop_words.update(catalan_stopwords)"
      ],
      "metadata": {
        "id": "os4JQ9h-4iXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function to preprocess text data. The text is converted to lower case, punctuation removed, tokenised using TextBlob, lemmatised, and stopwords removed."
      ],
      "metadata": {
        "id": "y9YupIHC-ebL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = TextBlob(text).words\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    lemmatized_tokens = [Word(word).lemmatize() for word in tokens]\n",
        "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "df['preprocessed_text'] = df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "lortiHDf4k9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply the calculate_sentiment function to the 'preprocessed_text' column of the DataFrame and store the sentiment labels in a new column 'afinn'."
      ],
      "metadata": {
        "id": "dP96wzVz-749"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now I calculate sentiments:\n",
        "df['afinn'] = df['preprocessed_text'].apply(lambda text: calculate_sentiment(text))"
      ],
      "metadata": {
        "id": "gwF62spb4uck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We ount the number of occurrences of each sentiment label ('Positive', 'Negative', 'Neutral') in the 'afinn' column."
      ],
      "metadata": {
        "id": "yRdt6-II_Eec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of positive, negative, and neutral sentiments for qualified\n",
        "sentiment_counts = df['afinn'].value_counts()\n",
        "sentiment_counts"
      ],
      "metadata": {
        "id": "mJxskowd4v7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation RoBERTuito**"
      ],
      "metadata": {
        "id": "eOhNORwF55RG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two dataframes are created with Spanish, and Catalan and bilingual instances, respectively, from the original dataframe 'df'."
      ],
      "metadata": {
        "id": "UqxvQpuv_InD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spanish = df[df['spanish'] == 1]\n",
        "cat_bi = df[df['spanish'] == 0]"
      ],
      "metadata": {
        "id": "xiowDFMz7j7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install and upload the necessary libraries."
      ],
      "metadata": {
        "id": "T9S1_YKk_R7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score"
      ],
      "metadata": {
        "id": "RS3MFdr86O8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy, F1 score and Confusion matrix are calculated for the overall manually labelled instaces ('df' dataframe), the Spanish instances ('spanish' dataframe), and the Catalan and bilingual instances ('cat_bi' dataframe) for RoBERTuito."
      ],
      "metadata": {
        "id": "BQkzTOXv_RLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#OVERALL\n",
        "#accuracy\n",
        "accuracy = accuracy_score(df['sentiment'], df['BERT'])\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "#f1\n",
        "f1_bert = f1_score(df['sentiment'], df['BERT'], average='weighted')\n",
        "print(\"F1 Score:\", f1_bert)\n",
        "\n",
        "#confusion matrix\n",
        "conf_matrix = confusion_matrix(df['sentiment'], df['BERT'])\n",
        "true_positives = conf_matrix[1, 1]\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"True Positives:\", true_positives)"
      ],
      "metadata": {
        "id": "rwtsoNFw5_fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Catalan & Bilingual\n",
        "\n",
        "#accuracy\n",
        "accuracy_b_cb = accuracy_score(cat_bi['sentiment'], cat_bi['BERT'])\n",
        "print(\"Accuracy:\", accuracy_b_cb)\n",
        "\n",
        "#f1\n",
        "f1_bert_catbi = f1_score(cat_bi['sentiment'], cat_bi['BERT'], average='weighted')\n",
        "print(\"F1 Score:\", f1_bert_catbi)\n",
        "\n",
        "#confusion matrix\n",
        "conf_matrix_b_cb = confusion_matrix(cat_bi['sentiment'], cat_bi['BERT'])\n",
        "true_positives_b_cb = conf_matrix_b_cb[1, 1]\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_b_cb)\n",
        "print(\"True Positives:\", true_positives_b_cb)"
      ],
      "metadata": {
        "id": "DScTTEgC6zKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spanish\n",
        "\n",
        "#accuracy\n",
        "accuracy_b_s = accuracy_score(spanish['sentiment'], spanish['BERT'])\n",
        "print(\"Accuracy:\", accuracy_b_s)\n",
        "\n",
        "#f1\n",
        "f1_bert_es = f1_score(spanish['sentiment'], spanish['BERT'], average='weighted')\n",
        "print(\"F1 Score:\", f1_bert_es)\n",
        "\n",
        "#confusion matrix\n",
        "conf_matrix_b_s = confusion_matrix(spanish['sentiment'], spanish['BERT'])\n",
        "true_positives_b_s = conf_matrix_b_s[1, 1]\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_b_s)\n",
        "print(\"True Positives:\", true_positives_b_s)"
      ],
      "metadata": {
        "id": "Muu-jPFH7KHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation AFINN**"
      ],
      "metadata": {
        "id": "dnxbwoMN57jT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy, F1 score and Confusion matrix are calculated for the overall manually labelled instaces ('df' dataframe), the Spanish instances ('spanish' dataframe), and the Catalan and bilingual instances ('cat_bi' dataframe) for AFINN."
      ],
      "metadata": {
        "id": "p8O3A6ICAKit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#OVERALL\n",
        "\n",
        "#accuracy\n",
        "accuracy_afinn = accuracy_score(df['sentiment'], df['afinn'])\n",
        "print(\"Accuracy:\", accuracy_afinn)\n",
        "\n",
        "#f1\n",
        "f1_afinn = f1_score(df['sentiment'], df['afinn'], average='weighted')\n",
        "print(\"F1 Score:\", f1_afinn)\n",
        "\n",
        "#confusion matrix\n",
        "conf_matrix_afinn = confusion_matrix(df['sentiment'], df['afinn'])\n",
        "true_positives_afinn = conf_matrix_afinn[1, 1]\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_afinn)\n",
        "print(\"True Positives:\", true_positives_afinn)"
      ],
      "metadata": {
        "id": "XSqRGzmX7NwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Catalan & Bilingual\n",
        "\n",
        "#accuracy\n",
        "accuracy_a_cb = accuracy_score(cat_bi['sentiment'], cat_bi['afinn'])\n",
        "print(\"Accuracy:\", accuracy_a_cb)\n",
        "\n",
        "#f1\n",
        "f1_afinn_es = f1_score(cat_bi['sentiment'], cat_bi['afinn'], average='weighted')\n",
        "print(\"F1 Score:\", f1_afinn_es)\n",
        "\n",
        "#confusion matrix\n",
        "conf_matrix_a_cb = confusion_matrix(cat_bi['sentiment'], cat_bi['afinn'])\n",
        "true_positives_a_cb = conf_matrix_a_cb[1, 1]\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_a_cb)\n",
        "print(\"True Positives:\", true_positives_a_cb)"
      ],
      "metadata": {
        "id": "sfQqVL-O8iKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spanish\n",
        "\n",
        "#accuracy\n",
        "accuracy_a_s = accuracy_score(spanish['sentiment'], spanish['afinn'])\n",
        "print(\"Accuracy:\", accuracy_a_s)\n",
        "\n",
        "#f1\n",
        "f1_afinn_catbi = f1_score(spanish['sentiment'], spanish['afinn'], average='weighted')\n",
        "print(\"F1 Score:\", f1_afinn_catbi)\n",
        "\n",
        "#confusion matrix\n",
        "conf_matrix_a_s = confusion_matrix(spanish['sentiment'], spanish['afinn'])\n",
        "true_positives_a_s = conf_matrix_a_s[1, 1]\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_a_s)\n",
        "print(\"True Positives:\", true_positives_a_s)"
      ],
      "metadata": {
        "id": "gZxrA7-D8i6-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}