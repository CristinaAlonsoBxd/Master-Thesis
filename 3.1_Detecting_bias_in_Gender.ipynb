{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We upload the data for the protected variable Gender got during the preprocessing as a dataframe. The names of the columns are: name, text, gender."
      ],
      "metadata": {
        "id": "xoSSlDyiQNDw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDTbkfNEkgio"
      },
      "source": [
        "**Uploading the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL-UEsWdOdLr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "gender_df = pd.read_excel('/content/ex_gender.xlsx')\n",
        "gender_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create two dataframes, one for women and another for men."
      ],
      "metadata": {
        "id": "hV8wSRFJQW4Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4hBjXKqOsOj"
      },
      "outputs": [],
      "source": [
        "women = gender_df[gender_df['gender'] == 1]\n",
        "men = gender_df[gender_df['gender'] == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvA3tNPIVzu0"
      },
      "source": [
        "## Descriptive statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We calculate the length of the text of women's notes."
      ],
      "metadata": {
        "id": "I-1zQS44QqDo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MLfpeY6EskT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "women['text_length'] = women['text'].str.len()\n",
        "women['text_length'].hist()\n",
        "plt.title('Histogram of Text Lengths for women')\n",
        "plt.xlabel('Length of Text')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "print(\"Average length:\", women['text_length'].mean())\n",
        "print(\"Median length:\", women['text_length'].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We count the average and media words in women's notes."
      ],
      "metadata": {
        "id": "BYND-NZWQu02"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMu2wMwCHs4t"
      },
      "outputs": [],
      "source": [
        "women['word_count'] = women['text'].apply(lambda x: len(str(x).split()))\n",
        "women['word_count'].hist()\n",
        "\n",
        "plt.title('Histogram word count for women')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "print(\"Average length:\", women['word_count'].mean())\n",
        "print(\"Median length:\", women['word_count'].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We calculate the length of the text for men's notes."
      ],
      "metadata": {
        "id": "z6dTlKOuQxxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9iY86yHFSLa"
      },
      "outputs": [],
      "source": [
        "men['text_length'] = men['text'].str.len()\n",
        "\n",
        "men['text_length'].hist()\n",
        "plt.title('Histogram of Text Lengths for men')\n",
        "plt.xlabel('Length of Text')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "print(\"Average length:\", men['text_length'].mean())\n",
        "print(\"Median length:\", men['text_length'].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We count the average and median words in men's notes."
      ],
      "metadata": {
        "id": "xuC5AmDVQ74P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5KQ3EdvH9I6"
      },
      "outputs": [],
      "source": [
        "men['word_count'] = men['text'].apply(lambda x: len(str(x).split()))\n",
        "men['word_count'].hist()\n",
        "\n",
        "plt.title('Histogram word count for men')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "print(\"Average length:\", men['word_count'].mean())\n",
        "print(\"Median length:\", men['word_count'].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTfsc0JE-ZHL"
      },
      "source": [
        "##Sentiment analysis\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBgRqfJK-qxa"
      },
      "source": [
        "**1. Pretrained BERT Pysentimiento**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install and import the necessary libraries."
      ],
      "metadata": {
        "id": "_54RPQkuQ_ZB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKf7tWxG0ufa"
      },
      "outputs": [],
      "source": [
        "!pip install pysentimiento\n",
        "\n",
        "from pysentimiento import create_analyzer\n",
        "import transformers\n",
        "\n",
        "transformers.logging.set_verbosity(transformers.logging.ERROR)\n",
        "\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply RoBERTuito for women and men's notes, respectively."
      ],
      "metadata": {
        "id": "j69gkV3PRGZR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWph2RDDV4jm"
      },
      "outputs": [],
      "source": [
        "###Sentiment in texts for women:\n",
        "positive_count = 0\n",
        "neutral_count = 0\n",
        "negative_count = 0\n",
        "\n",
        "for index, row in women.iterrows():\n",
        "    text = row['text']\n",
        "    result_women = analyzer.predict(text)\n",
        "\n",
        "    if result_women.output == 'POS':\n",
        "        positive_count += 1\n",
        "    elif result_women.output == 'NEU':\n",
        "        neutral_count += 1\n",
        "    elif result_women.output == 'NEG':\n",
        "        negative_count += 1\n",
        "\n",
        "print(\"Positive:\", positive_count)\n",
        "print(\"Neutral:\", neutral_count)\n",
        "print(\"Negative:\", negative_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvnzWuXoXHDn"
      },
      "outputs": [],
      "source": [
        "###Sentiment in texts for men:\n",
        "positive_count = 0\n",
        "neutral_count = 0\n",
        "negative_count = 0\n",
        "\n",
        "for index, row in men.iterrows():\n",
        "    text = row['text']\n",
        "    result_men = analyzer.predict(text)\n",
        "\n",
        "    if result_men.output == 'POS':\n",
        "        positive_count += 1\n",
        "    elif result_men.output == 'NEU':\n",
        "        neutral_count += 1\n",
        "    elif result_men.output == 'NEG':\n",
        "        negative_count += 1\n",
        "\n",
        "print(\"Positive:\", positive_count)\n",
        "print(\"Neutral:\", neutral_count)\n",
        "print(\"Negative:\", negative_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJbc4UMo-yWi"
      },
      "source": [
        "**2. AFINN with Spanish Lexicon**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install and import the necessary libraries."
      ],
      "metadata": {
        "id": "TdRnXc5ZRLhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQenbJHzXtqH"
      },
      "outputs": [],
      "source": [
        "####AFINN with spanish Lexicon\n",
        "!pip install textblob\n",
        "from textblob import TextBlob, Word\n",
        "\n",
        "!pip install nltk\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "import os\n",
        "stop_words = set(stopwords.words('spanish'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we initialise an empty dictionary to store FINN lexicon. Afterwards, we load the AFINN lexicon from a CSV file into a DataFrame. Only the first two columns are used. the, we iterate through each row of the DataFrame, extracting the word and its sentiment score."
      ],
      "metadata": {
        "id": "e2Yrd0bOROb-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5FkDDjPbHYI"
      },
      "outputs": [],
      "source": [
        "afinn = {}\n",
        "\n",
        "lexicon_df = pd.read_csv('/content/lexico_afinn.csv', header=0)\n",
        "lexicon_df = lexicon_df.iloc[:, :2]\n",
        "\n",
        "for index, row in lexicon_df.iterrows():\n",
        "    word = row['palabra']\n",
        "    sentiment_score_str = row['puntuacion']\n",
        "\n",
        "    try:\n",
        "        sentiment_score = float(sentiment_score_str)\n",
        "        afinn[word] = sentiment_score\n",
        "    except ValueError:\n",
        "        print(f\"Invalid sentiment score '{sentiment_score_str}' for word '{word}'. Skipping row.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function that calculates the sentiment of the text. First, convert the text to lowercase and split it into words. Then, calculate the sentiment score by summing the scores of individual words using the AFINN dictionary."
      ],
      "metadata": {
        "id": "BQ3Mv_G_RQVX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z17Hwv5Iao04"
      },
      "outputs": [],
      "source": [
        "def calculate_sentiment(text):\n",
        "    words = text.lower().split()\n",
        "    sentiment_score = sum(afinn.get(word, 0) for word in words)\n",
        "    if sentiment_score > 0:\n",
        "        return 'Positive'\n",
        "    elif sentiment_score < 0:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also upload stopwords for Catalan and add them to those for Spanish."
      ],
      "metadata": {
        "id": "kdLvhjIzRSeK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWbbPHM309wc"
      },
      "outputs": [],
      "source": [
        "catalan_stopwords = catalan_stopwords = [\n",
        "    'de', 'es', 'i', 'a', 'o', 'un', 'una', 'unes', 'uns', 'un', 'tot',\n",
        "    'també', 'altre', 'algun', 'alguna', 'alguns', 'algunes', 'ser', 'és',\n",
        "    'soc', 'ets', 'som', 'estic', 'està', 'estem', 'esteu', 'estan', 'com',\n",
        "    'en', 'per', 'perquè', 'per que', 'estat', 'estava', 'ans', 'abans',\n",
        "    'éssent', 'ambdós', 'però', 'per', 'poder', 'potser', 'puc', 'podem',\n",
        "    'podeu', 'poden', 'vaig', 'va', 'van', 'fer', 'faig', 'fa', 'fem',\n",
        "    'feu', 'fan', 'cada', 'fi', 'inclòs', 'primer', 'des de', 'conseguir',\n",
        "    'consegueixo', 'consigueix', 'consigueixes', 'conseguim', 'consigueixen',\n",
        "    'anar', 'haver', 'tenir', 'tinc', 'te', 'tenim', 'teniu', 'tene', 'el',\n",
        "    'la', 'les', 'els', 'seu', 'aquí', 'meu', 'teu', 'ells', 'elles', 'ens',\n",
        "    'nosaltres', 'vosaltres', 'si', 'dins', 'sols', 'solament', 'saber',\n",
        "    'saps', 'sap', 'sabem', 'sabeu', 'saben', 'últim', 'llarg', 'bastant',\n",
        "    'fas', 'molts', 'aquells', 'aquelles', 'seus', 'llavors', 'sota', 'dalt',\n",
        "    'ús', 'molt', 'era', 'eres', 'erem', 'eren', 'mode', 'bé', 'quant',\n",
        "    'quan', 'on', 'mentre', 'qui', 'amb', 'entre', 'sense', 'jo', 'aquell'\n",
        "]\n",
        "\n",
        "stop_words.update(catalan_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function to preprocess text data. The text is converted to lower case, punctuation removed, tokenised using TextBlob, lemmatised, and stopwords removed."
      ],
      "metadata": {
        "id": "ExLZTSV6RVaD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spTfpwf2bRi0"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = TextBlob(text).words\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    lemmatized_tokens = [Word(word).lemmatize() for word in tokens]\n",
        "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "women['preprocessed_text'] = women['text'].apply(preprocess_text)\n",
        "men['preprocessed_text'] = men['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply the calculate_sentiment function to the 'preprocessed_text' column of the two dataframes and store the sentiment labels in a new column 'sentiment'."
      ],
      "metadata": {
        "id": "EX0DeK8xRdhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A646G9QSUL0"
      },
      "outputs": [],
      "source": [
        "women['sentiment'] = women['preprocessed_text'].apply(lambda text: calculate_sentiment(text))\n",
        "men['sentiment'] = men['preprocessed_text'].apply(lambda text: calculate_sentiment(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We count the number of occurrences of each sentiment label ('Positive', 'Negative', 'Neutral') for women's notes."
      ],
      "metadata": {
        "id": "d-latZdiR0or"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRc-6JsLSecq"
      },
      "outputs": [],
      "source": [
        "sentiment_counts_women = women['sentiment'].value_counts()\n",
        "sentiment_counts_women"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We count the number of occurrences of each sentiment label ('Positive', 'Negative', 'Neutral') for men's notes."
      ],
      "metadata": {
        "id": "2xABrIUhR3as"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERbRKim1So41"
      },
      "outputs": [],
      "source": [
        "sentiment_counts_men = men['sentiment'].value_counts()\n",
        "sentiment_counts_men"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNe1dQ5PV_4Z"
      },
      "source": [
        "## Topic modelling and document embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Txq3fyw-4e6"
      },
      "source": [
        "**LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install and import the necessary libraries."
      ],
      "metadata": {
        "id": "WMvv3-t6SR4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vMTyk_g0VKc"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.models.ldamodel import LdaModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use LDA for topic modelling, following the following steps:"
      ],
      "metadata": {
        "id": "m5GvMFZVSTHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9EHpEAZTyRM"
      },
      "outputs": [],
      "source": [
        "#Firstly we tokenize the text\n",
        "def tokenize_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "women['tokenized_text'] = women['preprocessed_text'].apply(tokenize_text)\n",
        "men['tokenized_text'] = men['preprocessed_text'].apply(tokenize_text)\n",
        "\n",
        "#We create dictionary representation of the documents\n",
        "dictionary_women = Dictionary(women['tokenized_text'])\n",
        "dictionary_men = Dictionary(men['tokenized_text'])\n",
        "\n",
        "dictionary_women.filter_extremes(no_below=4, no_above=0.4)\n",
        "dictionary_men.filter_extremes(no_below=4, no_above=0.4)\n",
        "\n",
        "#We convert the dictionary to a bag of words corpus\n",
        "corpus_women = [dictionary_women.doc2bow(doc) for doc in women['tokenized_text']]\n",
        "corpus_men = [dictionary_men.doc2bow(doc) for doc in men['tokenized_text']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we apply the LDA model, and represent 2 topics for women and men's notes, respectively:"
      ],
      "metadata": {
        "id": "SvaqaRwASgC8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBFdrVNKVu1L"
      },
      "outputs": [],
      "source": [
        "num_topics = 2\n",
        "\n",
        "#LDA in women\n",
        "lda_women = LdaModel(corpus_women, num_topics=num_topics, id2word=dictionary_women, passes=10)\n",
        "\n",
        "#LDA in men\n",
        "lda_men = LdaModel(corpus_men, num_topics=num_topics, id2word=dictionary_men, passes=10)\n",
        "\n",
        "#Topics for women\n",
        "print(\"Women Topics:\")\n",
        "for i, topic in lda_women.print_topics(num_words=10):\n",
        "    print(f\"Topic {i}: {topic}\")\n",
        "\n",
        "#Topics for men\n",
        "print(\"Men Topics:\")\n",
        "for i, topic in lda_men.print_topics(num_words=10):\n",
        "    print(f\"Topic {i}: {topic}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**t-SNE**"
      ],
      "metadata": {
        "id": "PLotXDkA7F4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install and import the necessary libraries:"
      ],
      "metadata": {
        "id": "RnoZRIcuSsMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "kpTUoqKS7INd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We preprocess the text in the age_df dataframe, and then we vectorise it."
      ],
      "metadata": {
        "id": "jywHzoppSt1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gender_df['preprocessed_text'] = gender_df['text'].apply(preprocess_text)\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(gender_df['preprocessed_text'])"
      ],
      "metadata": {
        "id": "sxUCYS098fks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply T-SNE and plot it."
      ],
      "metadata": {
        "id": "0YW_K9huSvcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "\n",
        "tsne_results = tsne.fit_transform(tfidf_matrix.toarray())\n",
        "\n",
        "gender_df['tsne_1'] = tsne_results[:, 0]\n",
        "gender_df['tsne_2'] = tsne_results[:, 1]\n",
        "\n",
        "#plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = sns.scatterplot(\n",
        "    x='tsne_1', y='tsne_2',\n",
        "    hue='gender',\n",
        "    palette=sns.color_palette(\"hls\", 2),\n",
        "    data=gender_df,\n",
        "    legend=\"full\",\n",
        "    alpha=0.6\n",
        ")\n",
        "\n",
        "handles, labels = scatter.get_legend_handles_labels()\n",
        "labels = ['Women', 'Men']\n",
        "scatter.legend(handles, labels, title=\"Gender\")\n",
        "\n",
        "plt.title('t-SNE visualization of topics for each gender')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZV-SXZ2n9lW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic regression\n",
        "\n",
        "We intend to predict if the patient category 'Women' or 'Men', from the text. Firstly, we import the necessary libraries."
      ],
      "metadata": {
        "id": "LLCN7hqz8zyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "YsT2LxgS8zcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we follow the next steps to train the logistic regression model, make predictions, and get a confusion matrix and accuracy score."
      ],
      "metadata": {
        "id": "KxCTcQ1tS_P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(gender_df['text'], gender_df['gender'], test_size=0.2, random_state=42)\n",
        "\n",
        "#Preprocess text and convert to numerical features using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "#Train logistic regression model\n",
        "logreg_model = LogisticRegression()\n",
        "logreg_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "#Make predictions on the test set\n",
        "predictions = logreg_model.predict(X_test_tfidf)\n",
        "\n",
        "#Evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "#Get the onfusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "true_positives = conf_matrix[1, 1]\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"True Positives:\", true_positives)"
      ],
      "metadata": {
        "id": "iTsowcUG89So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we build a classification report, and we get the accuracy for the groups women patients and men patients."
      ],
      "metadata": {
        "id": "3_gSTMPqTXdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_report = classification_report(y_test, predictions, target_names=['Men', 'Women'])\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "#Extract values from the confusion matrix\n",
        "TN = conf_matrix[0, 0]  #True Negatives for men\n",
        "FP = conf_matrix[0, 1]  #False Positives for men (incorrectly predicted as women)\n",
        "FN = conf_matrix[1, 0]  #False Negatives for women (incorrectly predicted as men)\n",
        "TP = conf_matrix[1, 1]  #True Positives for women\n",
        "\n",
        "#Calculate accuracy for each group\n",
        "accuracy_men = TN / (TN + FP)\n",
        "accuracy_women = TP / (TP + FN)\n",
        "\n",
        "print(f'Accuracy for texts from men: {accuracy_men}')\n",
        "print(f'Accuracy for texts from women: {accuracy_women}')"
      ],
      "metadata": {
        "id": "e9kTwDt68_Tz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}